---
link: https://www.notion.so/R23-W03-9c3e90b24dc54ac9aa90d106a1eb54e3
notionID: 9c3e90b2-4dc5-4ac9-aa90-d106a1eb54e3
---
### RAMDISK 환경에서의 실험으로 다양한 결과 및 결론, 의문을 만들었다.

##### #20, 21, 22: 고꾸라지는 성능이 재현되었으며 blktrace/iowatcher로 분석해보았다.
- Ramdisk에서 실험하였을 때, 성능이 고꾸라지는 문제가 재현이 됨
- blktrace의 결과
	- normal에서와 달리 random에서는 io가 아예 발생을 안하는 시간이, 그것도 꽤 길게 나타난다.
	- **writeback 과정을 random의 어떤 상황이 방해하는가?**
- norandommap 옵션으로도 실험해봄
	- random에서 성능이 증가함
	- 중간에 io 발생을 안하는 시간이 사라졌음
	- 히스토리를 기반으로 write하면 짧은 시간 안에, 같은 곳을 두 번 접근하는 일이 사라져서 random-NOT에서 active의 수가 줄어들게 되어 발생하는 현상이라 추측
		- => file offset 접근을 찍어서 확인해보려 했지만 실패. 일단은 맞는 추측이라 가정


blktrace로 찍은 write offset
왼쪽 위부터 normal, normal_wordmap, random, random_wordmap
![[Screenshot from 2023-01-25 10-33-21.png]]
![[Screenshot from 2023-01-25 10-33-37.png]]

##### #23, 24: ftrace로 fio의 파일 접근 패턴 분석을 시도해 보았으나 결론은 뭔가 이상하고 잘 모르겠다이다. 
- 스토리지의 block offset이 아니라 파일의 오프셋에서의 접근 패턴을 분석 시도해보았다.
	- ftrace로 ext4_da_write_begin함수가 불릴 때마다의 inode와 offset을 뜯어내었다.
	- 모든 파일의 offset은 0부터 시작해서 중복 되기 때문에 inode number x 각 파일의 사이즈 + offset으로 식별하였다.
	- ext4_da_write_begin은 페이지 캐시를 찾기 이전에 수행하므로, hit나면 생략된다거나 하는 일은 발생하지 않는다.

- 확실히 그냥 random보다 random_wo이 더 드문드문 해보인다. 
	- => 짧은 시간에 같은 offset에 접근하는 일이 더 드물다. 
	- => active로 전환되는 일이 더 적다.
	- 라고 추론
	
- normal은 특정 시기에 특정 파일만을 접근하는 것 같다.
	- => 특정 파일은 특정 프로세스만 접근한다.
	- => 대부분의 코어가 다 노는 건 아닐까?
	
- mpstat으로 코어의 사용률을 확인해 보았을 때, 절대값 자체는 normal이 높지만 throughput (처리한 request양) 대비해서 살펴보았을 때는 random 보다는 작다.
	- 아래 그림들 중 전체코어를 사용하게 돌렷을 때의 그림에서 보이는 드라마틱한 차이는 나타나지 않는다.
	- 대부분의 코어가 다 논다고 할 수는 없다.
	
- normal 같은 경우 파일 offset에 접근 안 하는 상황이 중간에 너무 길게 나타나 보인다.
	- 혹시나 너무 메모리를 과하게 사용해서 ftrace가 제대로 캐치를 못했을까봐 2개의 thread로만 fio를 수행하도록 하고 ftrace를 돌림
	- 아래 그림들 중 2t에 해당하는 그림이그것인데 그렇다고 해도 노는 상황이 중간중간 꽤 있다. 모든 패턴에서...

- 결과적으로 각 패턴들 사이의 차이는 분명 눈에 띄게 존재하지만, 이게 정말 신뢰할 수 있는 접근 패턴인 것인지, 그게 맞다면 저 이상한 특성들을 어떻게 설명할 수 있을지는 알 수 없다.


![[Screenshot from 2023-01-25 10-31-25.png]]
![[Screenshot from 2023-01-25 10-32-04.png]]


##### #25: ftrace로 shrink inactive list의 stat 값을 살펴보았다.
- nr_reclaim, nr_dirty, nr_active 사이의 상관 관계만 눈에 띄게 유추가 되며, 크게 도움이 될만한 다른 인사이트는 없다. 코드 분석에는 도움이 될 듯 하다.


### 결론
- random-NOT가 느린 이유를 아래와 같이 결론 내린다.  
	1. kswapd가 메모리를 비울려고 하지만 inactive의 대부분이 다시금 active로 넘어간다(dirty 라서). (코드 확인 필요)  
	2. active의 숫자가 늘어나고, 비울려고 하는 시도가 늘어나기 때문에 그만큼 lock을 자주 많이 잡게 된다.  
	3. lock을 많이 잡고 있어서 page cache를 add하는 write가 오래걸린다.  
	4. kswapd가 메모리를 빨리 비워주지 못해서 try_to_do_free_pages가 write에서 자주 불린다.  
- => 모든 원인은 1번

- 환경마다 random-NOT의 성능이 고꾸라지거나 급상승하거나 왔다갔다 하는 이유를 아래와 같이 결론 내린다.  
	1. 위 1번이 많이 발생하는 상황의 확률이 높으면 고꾸라진다.  
	2. 코어수가 많아서 lock 컨텐션이 높아지면 고꾸라진다.

- **To-do**는 위클리에서 정리하면서 생각해내는건 맞지만 중복되지 않게 트렐로로만 관리한다.