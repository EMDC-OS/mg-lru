---
link: https://www.notion.so/R23-01-09-c5e26809cbf947c9b7898a87330f0827
notionID: c5e26809-cbf9-47c9-b789-8a87330f0827
---
#14
##### I/O Throttling 분석
- [https://lwn.net/Articles/456904/](https://lwn.net/Articles/456904/)
- 기존에 I/O Throttling을 해야하는 (구현한) 이유?
	1. Terrible한 I/O pattern을 피하기 위해? => 그러면 IOTrace로 vanilla와 NOT 버전 체크, 어떠한 패턴이 나오는가?
		- **I/O throttling을 하든, 하지 않든 상관 없이 direct reclaim을 제외하고는(iou-wrk, 즉 fio가 직접 수행하는 작업을 direct reclaim이라고 생각했을 때) write를 항상 kworker가 하고 있다.** => 어차피 direct reclaim이 아닌 이상에야 throttling을 하지 않아도 큰 random pattern이 나타나지는 않는다. 
	2. 위 가정이 맞다면? => 이러한 I/O pattern을 seq하게 만드는게 정말 성능상으로 크게 차이가 나는가? 아니면 I/O pattern은 크게 관계 없고, 이제는 메모리만이 문제인가?  <= 가정이 틀리다.

#15
- blktrace를 이용한 분석 결과
	- blktrace에 찍히는 write 개수가 not가 당연히 더 많을줄 알았는데, van에서 훨씬 많았다. (노말이든 랜덤이든 노상관)
	- 또 특이한점은 normal과 달리 random에서는 not에서 Read도 기하급수적으로 많이 증가하는 모습을 보엿다. => 메모리에서 쫓겨나서 다시 읽어들여지는 애들인가?
	- Random을 수행했을 때 trace line 수
		1. van / read: 117, write: 39,224,115
		2. not / read: 195,588 (1000배 이상), write: 5,047,822 (1/8)
	
1. 왜 실제 디스크 라이트 수가 not에서 줄어들어?
2. 왜 not의 random에서 read가 엄청 늘어?


#16
##### Finer LRU와의 비교
1. Finer-LRU는 성능은 좋긴해
2. 근데 리스트를 몇개로 할지 튜닝해야하는 문제가 있고, 갯수를 유동적으로 조절할 수 없어
3. cgroup을 나누면 그 cgroup마다 그 많은 리스트 수가 존재하니까 오버헤드가 커져
