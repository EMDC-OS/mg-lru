---
link: https://www.notion.so/R23-01-10-3ebdb1d62188477a8d9b44a3158823a7
notionID: 3ebdb1d6-2188-477a-8d9b-44a3158823a7
---
#17
##### VAN 대비 NOT에서 실제 DISK Write 수가 줄어드는 이유?
- VAN과 NOT의 실제 Disk write 값은
	- random
		- van: 94255884 (7.63)
		- not: 12352129 
	- normal
		- van: 98236114 (2.49)
		- not: 39410269
- VAN과 NOT의 in_queue 값은
	- random
		- van: 184344641
		- not: 19853942
	- normal
		- van: 184551721
		- not: 7387279
- 첫 번째 의심: 원래 van에서 였다면 writeback 되었어야 하는 애들이, redirty되어서 writeback되지 않는다?
	1. writeback은 expired 시간이 지난 애들만 디스크에 쓰는걸로 알고 있었는데 그 단위가 페이지 단위야? 그렇지 않다면 이 가정이 틀린거 아닌가?
		- 일단 코드상으로는 아이노드 단위로 시간 체크하는 건 맞음.
		- 그래서 일단 틀림? => zipf 보고 normal 보다 차이가 적으면 아직 비슷한 이유가 가능성 있을지도 => zipf도 결국 normal과 비슷한 disk write 수 변화 패턴... 즉 틀린 의심인듯
- 두 번째 의심: 뭔가 다른 디스크에 I/O를 내리는 어떤 부분에서 느려졌다.

=> 걍 위에서 fio의 디스크 write로 찍히는건 ios 즉 io요청 횟수를 나타내고 있었고, NOT의 경우 한 번의 요청을 내릴 때 사이즈를 크게크게 내리기 때문에 ios가 상대적으로 적은 것 뿐이었다
blktrace의 Queueing 이벤트들 중 10번째 컬럼 즉 섹터 수의 평균을 내보았을 때 VAN과 NOT의 차이는 다음과 같다.
- random
	- van: 10.0871
	- not: 78.3267 (7.76)
- normal
	- van: 8.95727
	- not: 18.9975 (2.12)
- 위 ios 값과 거의 정확하게 반비례하여 차이가 난다.

#18
##### NOT에서 Random을 돌렸을 때만 read가 많이 보이는 이유 (write가 겹치지 않는 오프셋에)

![[Pasted image 20230110154028.png]]
- 위 그림은 NOT에서 random write을 돌렸을 때 마지막 30초의 read/write offset을 찍은 것이다. (초록색이 read라 추정)
- 다른 패턴의 wirte에서는 보이지 않던 100000~285000부분에의 read가 많이 보였었다.

![[Pasted image 20230110154204.png]]
- 위 그림은 VAN에서 random write을 돌렸을 때 초반 10초의 read/write offset을 찍은 것이다. (파란색이 read라 추정)
- 초반에 100000~285000에 read가 엄청 발생한다. => 즉 처음에 추정했던 fio 파일들의 메타데이터 블록이 맞다고 보면 될 것 같다.