---
link: https://www.notion.so/R23-02-02-d810a4635f584f47b6281c272f83b5da
notionID: d810a463-5f58-4f47-b628-1c272f83b5da
---
#33
##### dirty_ratio에 따른 성능 차이
- 메모리의 5배 크기의 fileset, 10분 ramp up, 10분 러닝 했을 때  dirty_ratio을 키운 것과 디폴트가 성능 차이가 나지 않는다.
- 메모리의 5배 크기의 fileset, 3분 ramp up, 3분 러닝 했을 때도 마찬가지로 성능 차이가 나지 않는다 => 성능이 staturation
- 더 정확한 상황 설명은 다음과 같다
	- I/O throttling은 dirty_background_ratio와 dirty_ratio로 정해지는 setpoint에 dirty페이지 수를 유지하려고 한다.
	- 만약 현재 시스템의 dirty페이지 수가 setpoint에 도달한다면, I/O throttling은 write thread들의 총 throughput을 block device의 밴드위스에 맞춘다.
	- 따라서 충분히 큰 사이즈로 돌리면 dirty를 많이 유지하는데에 대한 hit이점도 없고, 길게 돌리면 dirty page수를 setpoint에 유지한 상태로 계속 성능이 측정되므로, dirty_ratio에 상관없이 성능이 높게 나온다.
	- 다만 이해가 되지 않는건 있다.
		- 작은 파일셋으로 돌렸더라도, 3분이면 어느정도 saturation된 상황이었을테고, dirty 사용률에만 차이가 있을 뿐 어차피 전체 메모리 사용량에는 차이가 없을텐데 왜 성능의 차이가 나는거지? 즉 hit ratio에는 차이가 없을텐데. => (기회를 한 번 더 받는 애들이 많아지고, 그래서 히트율이 높아졌다는 추측!)
- 다만, ZSSD(빠른 디바이스)에서 다음과 같은 필요성에 대해 탐색해보려 한다.
	- ZSSD에서 16thread로 메모리의 5배 크기의 파일 셋에  write를 할 때 쓰루풋이 대략 1.2GB나온다.
	- 970 evo에서도 16thread로 메모리의 5배 크기의 파일 셋에 write를 할 때 쓰루풋이 대략 1.2GB나온다.
	- ZSSD의 /dev 디렉토리의 블록 디바이스 파일에 직접 fio로 돌린다면 쓰루풋이 대략 8GB만큼 나온다.
	- 위와 같은 실험 결과에 따라서 다음과 같은 결론을 내렸었다.
		- writeback thread가 하나라서 디바이스의 성능을 충분히 뽑지 못한다.
	- 그래서 direct I/O로 같은 환경에서 ZSSD로 실험을 했었는데 마찬가지로 성능이 1.2GB에 가깝게 나왔다.
		- 그래서 위 추측이 틀렸나? 그 이유(wb flusher 하나) 때문에 낮게 나오는게 아닌가?
	- => blktrace와 iowatcher로 각 실험들에 대해서의 상황을 구체적으로 살펴본다.